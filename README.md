# Air Writing Recognition

Our project, Air Gesture Recognition, aims to use a combination of computer vision and handwriting recognition to create model that recognizes gestures written in air as text. Model users would be able to write “air words” facing a web-camera either real time or in-advance and have those gestures translated into character digits or words. 

To us, air gesture recognition is an interesting topic to create a solution for because it lends itself to many different future uses. Most intuitively, air gesture analysis allows for users with specific needs alternative forms of communication. This idea could also be extrapolated into using air gestures as a more universal input interface for technologies that are unsuited for the traditional keyboard and mouse (such as AR and VR systems).


<!-- ## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

### Prerequisites

What things you need to install the software and how to install them

```
Give examples
```

### Installation

A step by step series of examples that tell you how to get a development env running

Say what the step will be

```
Give the example
```

And repeat

```
until finished
```

End with an example of getting some data out of the system or using it for a little demo

## Ready, set, run!

Explain how to run the automated tests for this system -->


## Built With

* [OpenCV](http://www.opencv.com) - The computer vision library used

## Authors

* **Michelle Jin**  [Github - mjin8](https://github.com/mjin8/)
* **Crystal Lin**   [Github - heycrystal](https://github.com/heycrystal/)

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## Acknowledgments

* Hat tip to anyone whose code was used
* Inspiration
* etc

